{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Dataloader for the International Tree-Ring Data Bank (ITRDB)\n",
        "\n",
        "This data works by wrapping our parsed ITRDB data in a PyTorch Dataset to be used for PyTorch Neural Networks. The parsed data is publicly hosted on an AWS S3 bucket, and is retrieved simply through the Python requests library. The Dataset will also cache the created dataframe, so the API request will only need to be made once per session, enabling you to create multiple Datasets (train, test, and validate) with little to no wait time. For the sake of simplicity, this Dataset will also limit the tree ring widths to between the years 1900-2023, and will then drop any rings that have 0 measurements between that time (row is all NaN between 1900-2023)"
      ],
      "metadata": {
        "id": "20MIgRI9-qFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary dependencies"
      ],
      "metadata": {
        "id": "d8JPzo-5BBBk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "YhHsRPgzsVuz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import requests\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset Class itself, we retrieve the data from S3, cache it, and write a split function that can produce a 70-15-15 split on the data, only saving the set type requested in the constructor's parameters:"
      ],
      "metadata": {
        "id": "RM7yIi-UBHkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "QhqOoUy0r9Td"
      },
      "outputs": [],
      "source": [
        "class TreeRingDataset(Dataset):\n",
        "\n",
        "  _cache = None\n",
        "  _train = None\n",
        "  _test = None\n",
        "  _validate = None\n",
        "\n",
        "  def __init__(self, set_type=\"train\"):\n",
        "\n",
        "    if TreeRingDataset._cache is None:\n",
        "      res = requests.get(\"https://paleo-data.s3.amazonaws.com/data.csv\")\n",
        "      TreeRingDataset._cache = pd.read_csv(StringIO(res.text), sep=\",\")\n",
        "\n",
        "    self.df = TreeRingDataset._cache.copy()\n",
        "\n",
        "    self.df.drop(self.df.columns[list(range(1, 1940))], axis=1, inplace=True)\n",
        "    self.df.dropna(subset=self.df.columns[1:52], how='any', inplace=True)\n",
        "\n",
        "    if type(TreeRingDataset._train) == type(None):\n",
        "      print(\"Performing a Split\")\n",
        "      TreeRingDataset._train, TreeRingDataset._test, TreeRingDataset._validate = self.__split()\n",
        "\n",
        "    self.df = TreeRingDataset._train if set_type == \"train\" else (TreeRingDataset._test if set_type == \"test\" else TreeRingDataset._validate)\n",
        "\n",
        "\n",
        "  def __split(self):\n",
        "    train, test = train_test_split(self.df, train_size=.70)\n",
        "    validate, test = train_test_split(test, train_size=.5)\n",
        "    return (train, test, validate)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = torch.tensor(self.df.iloc[index, 1:52])\n",
        "    latn, lats, lone, lonw = self.df.iloc[index, 87:91]\n",
        "    label = torch.tensor([(latn+lats)/2, (lone+lonw)/2])\n",
        "\n",
        "    return x, label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then this can be taken and retrieved for each train, test, and validate set, which will only need to send 1 API request and thus finish fairly quickly:"
      ],
      "metadata": {
        "id": "qsvkesqqBTYY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "N-c_t2w2tIh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b861e1-8816-464a-de27-6c3bbd557f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing a Split\n"
          ]
        }
      ],
      "source": [
        "train_data = TreeRingDataset(\n",
        "    set_type=\"train\"\n",
        ")\n",
        "\n",
        "test_data = TreeRingDataset(\n",
        "    set_type=\"test\"\n",
        ")\n",
        "\n",
        "validate_data = TreeRingDataset(\n",
        "    set_type=\"validate\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can wrap it in a Dataloader:"
      ],
      "metadata": {
        "id": "2o3K3qUlBf6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size=32)\n",
        "test_dataloader = DataLoader(test_data, batch_size=32)\n",
        "validate_dataloader = DataLoader(validate_data, batch_size=32)"
      ],
      "metadata": {
        "id": "Mj1G85qX7dBH"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And just an example of what the data looks like, we can display the first batch:"
      ],
      "metadata": {
        "id": "RIy43ZNnBjrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(train_features)\n",
        "print(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQwUvKb56hoF",
        "outputId": "cd4a522e-7042-4dee-bd7a-5311edc04ab8"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.0700, 1.8200, 1.9400,  ..., 1.5900, 0.8500, 1.3300],\n",
            "        [0.6320, 1.0950, 1.0200,  ..., 0.5740, 0.6440, 0.5190],\n",
            "        [0.6200, 0.7100, 0.4600,  ..., 0.4900, 0.5500, 0.5000],\n",
            "        ...,\n",
            "        [0.2700, 0.2500, 0.2400,  ..., 0.4400, 0.3200, 0.3200],\n",
            "        [0.4000, 0.3400, 0.4400,  ..., 0.2300, 0.0900, 0.3700],\n",
            "        [0.6030, 0.6760, 0.3060,  ..., 0.2580, 0.4550, 0.3760]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[  36.6000, -118.7000],\n",
            "        [  38.3800, -108.0200],\n",
            "        [  41.8700, -110.8000],\n",
            "        [  40.1417, -111.3333],\n",
            "        [  40.0500, -108.3000],\n",
            "        [  48.6800, -120.6300],\n",
            "        [  24.7140,  -81.3850],\n",
            "        [  39.8300, -108.2000],\n",
            "        [  37.8300, -119.2200],\n",
            "        [  37.2000, -112.8000],\n",
            "        [  48.6800, -120.6300],\n",
            "        [  43.3042, -110.6711],\n",
            "        [  58.4410, -135.6090],\n",
            "        [  37.6596, -112.8560],\n",
            "        [  34.9738,  -77.1201],\n",
            "        [  44.6000, -110.4000],\n",
            "        [  44.9140, -109.5730],\n",
            "        [  34.8370, -119.0480],\n",
            "        [  42.9167, -109.8000],\n",
            "        [  29.2800,  -82.6300],\n",
            "        [  37.1000,  -91.1000],\n",
            "        [  39.3770, -123.8040],\n",
            "        [  40.4200, -105.5700],\n",
            "        [  37.7700, -119.8000],\n",
            "        [  44.7000, -118.5500],\n",
            "        [  37.3800, -118.1700],\n",
            "        [  37.7500, -119.8500],\n",
            "        [  44.9140, -109.5730],\n",
            "        [  40.8000, -105.1800],\n",
            "        [  44.9140, -109.5730],\n",
            "        [  37.5500, -105.4200],\n",
            "        [  24.7140,  -81.3850]], dtype=torch.float64)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
